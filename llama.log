[1710459694] 
llama server listening at http://127.0.0.1:35634

[1710459695] warming up the model with an empty run
[1710459695] Available slots:
[1710459695]  -> Slot 0 - max context: 4096
[1710459695] all slots are idle and system prompt is empty, clear the KV cache
[1710459713] slot 0 is processing [task id: 0]
[1710459713] slot 0 : in cache: 0 tokens | to process: 138 tokens
[1710459713] slot 0 : kv cache rm - [0, end)
[1710459717] sampled token:  5801: ' Good'
[1710459717] sampled token:  3970: ' morning'
[1710459718] sampled token: 28725: ','
[1710459718] sampled token:   367: ' P'
[1710459718] sampled token:  1292: 'uff'
[1710459718] sampled token: 28808: '!'
[1710459718] sampled token:  4867: ' Are'
[1710459718] sampled token:   368: ' you'
[1710459719] sampled token:  4622: ' feeling'
[1710459719] sampled token: 24343: ' refres'
[1710459719] sampled token:   887: 'hed'
[1710459719] sampled token:  1024: ' after'
[1710459719] sampled token:   264: ' a'
[1710459719] sampled token:  1179: ' good'
[1710459720] sampled token:  2125: ' night'
[1710459720] sampled token: 28742: '''
[1710459720] sampled token: 28713: 's'
[1710459720] sampled token:  4289: ' sleep'
[1710459720] sampled token: 28804: '?'
[1710459721] sampled token:   315: ' I'
[1710459721] sampled token:  3317: ' hope'
[1710459721] sampled token:   586: ' my'
[1710459721] sampled token:  3345: ' services'
[1710459721] sampled token:  1432: ' last'
[1710459721] sampled token:  2125: ' night'
[1710459721] sampled token:   654: ' were'
[1710459722] sampled token:  4864: ' satisf'
[1710459722] sampled token:  3765: 'actory'
[1710459722] sampled token: 28723: '.'
[1710459722] sampled token: 28705: ' '
[1710459722] sampled token:   243: 'ð'
[1710459722] sampled token:   162: 'Ÿ'
[1710459723] sampled token:   149: '’'
[1710459723] sampled token:   167: '¤'
[1710459723] sampled token: 30816: 'âœ¨'
[1710459723] sampled token:     2: ''
[1710459723] 
[1710459723] print_timings: prompt eval time =    4104.38 ms /   138 tokens (   29.74 ms per token,    33.62 tokens per second)
[1710459723] print_timings:        eval time =    5918.44 ms /    36 runs   (  164.40 ms per token,     6.08 tokens per second)
[1710459723] print_timings:       total time =   10022.82 ms
[1710459723] slot 0 released (171 tokens in cache)
